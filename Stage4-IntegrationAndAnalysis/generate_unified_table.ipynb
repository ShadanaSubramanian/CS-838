{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "A = em.read_csv_metadata('/Users/daravinds/Documents/Projects/CS-838/Stage3-EntityMatching/CS-838-bookdepository.csv',key='id')\n",
    "B = em.read_csv_metadata('/Users/daravinds/Documents/Projects/CS-838/Stage3-EntityMatching/CS-838-goodreads.csv',key='id') \n",
    "\n",
    "# A = A.replace(np.nan, '', regex=True)\n",
    "# B = B.replace(np.nan, '', regex=True)\n",
    "A['Language'] = A['Language'].fillna('')\n",
    "B['Language'] = B['Language'].fillna('')\n",
    "\n",
    "A['Publishing Date'] = A['Publishing Date'].fillna('')\n",
    "B['Publishing Date'] = B['Publishing Date'].fillna('')\n",
    "\n",
    "A['Publisher'] = A['Publisher'].fillna('')\n",
    "B['Publisher'] = B['Publisher'].fillna('')\n",
    "\n",
    "A['Genres'] = A['Genres'].fillna('')\n",
    "B['Genres'] = B['Genres'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "I = em.read_csv_metadata(\"train_set.csv\", \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after=['match'])\n",
    "\n",
    "# Impute feature vectors with the mean of the column values.\n",
    "H = em.impute_table(H, \n",
    "                exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "\n",
    "# Train using feature vectors from I \n",
    "lg.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "       target_attr='match')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = em.read_csv_metadata(\"after_blocking_tuples.csv\", \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F, show_progress=False)\n",
    "L = L.fillna(0)\n",
    "em.set_property(L, 'key', '_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id'], \n",
    "              append=True, target_attr='predicted', inplace=False, return_probs=True,\n",
    "                        probs_attr='proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(predictions['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions)\n",
    "matches_df = df.loc[df['predicted'] == 1]\n",
    "\n",
    "match_map = dict()\n",
    "for index, match in matches_df.iterrows():\n",
    "    if match['ltable_id'] in match_map:\n",
    "        existing_matches = match_map.get(match['ltable_id'])\n",
    "    else:\n",
    "        existing_matches = set()\n",
    "    existing_matches.add(match['rtable_id'])\n",
    "    match_map[match['ltable_id']] = existing_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = set()\n",
    "for values in match_map.values():\n",
    "    for value in values:\n",
    "        all_values.add(value)\n",
    "\n",
    "A_ids = set(A['id'])\n",
    "A_matched_ids = set(match_map.keys())\n",
    "ltable_ids_without_match = A_ids.difference(A_matched_ids)\n",
    "\n",
    "B_ids = set(B['id'])\n",
    "B_matched_ids = all_values\n",
    "rtable_ids_without_match = B_ids.difference(B_matched_ids)\n",
    "\n",
    "merged_data = pd.DataFrame()\n",
    "data_from_A = pd.DataFrame(A.loc[A['id'].isin(ltable_ids_without_match)], columns=[\"Title\", \"Authors\", \"Genres\", \"Publishing Date\", \"Pages\", \"Publisher\", \"Language\"])\n",
    "data_from_B = pd.DataFrame(B.loc[B['id'].isin(rtable_ids_without_match)], columns=[\"Title\", \"Authors\", \"Genres\", \"Publishing Date\", \"Pages\", \"Publisher\", \"Language\"])\n",
    "\n",
    "# print(len(A), len(B))\n",
    "# print(len(data_from_A), len(data_from_B))\n",
    "# print(len(ltable_ids_without_match), len(rtable_ids_without_match))\n",
    "# print(len(match_map), len(all_values))\n",
    "\n",
    "merged_data = data_from_A.append(data_from_B, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_map\n",
    "# for l_id, r_ids in match_map.items():\n",
    "#     records = list()\n",
    "#     for r_id in r_ids:\n",
    "#         records = list()\n",
    "#         records.append(A.loc[A['id'] == l_id])\n",
    "#         records.append(B.loc[A['id'] == r_id])\n",
    "#         final_record = merge_tuples(records)\n",
    "#         print(final_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_tuples(records):\n",
    "#     final_title = merge_titles(records)\n",
    "#     authors = merge_authors(records)\n",
    "#     genres = merge_genres(records)\n",
    "#     publishing_date = merge_publishing_dates(records)\n",
    "#     pages = merge_pages(records)\n",
    "#     publisher = merge_publishers(records)\n",
    "#     language = merge_languages(records)\n",
    "#     return tuple(final_title, authors, genres, publishing_date, pages, publisher, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_titles(records):\n",
    "    length = 0\n",
    "    for record in records:\n",
    "        cur_title = record['Title'].strip()\n",
    "        if len(cur_title) > length:\n",
    "            length = len(cur_title)\n",
    "            title = cur_title\n",
    "#         .to_string(index = False)\n",
    "#         if title is not None and len(title) > 0:\n",
    "#             return title\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_authors(records):\n",
    "    authors = list()\n",
    "    length = 0\n",
    "    for record in records:\n",
    "        current_authors = record['Authors'].strip().split(\":\")\n",
    "#         .to_string(index = False).split(\":\")\n",
    "        if len(current_authors) > length:\n",
    "            length = len(current_authors)\n",
    "            authors = \":\".join(current_authors)\n",
    "    return authors\n",
    "            \n",
    "#     A_authors = records[-1]['Authors'].to_string(index = False).split(\":\")\n",
    "#     B_authors = records[0]['Authors'].to_string(index = False).split(\":\")\n",
    "    \n",
    "#     if len(A_authors) > len(B_authors):\n",
    "#         authors = A_authors\n",
    "#     else:\n",
    "#         authors = B_authors\n",
    "#     return \":\".join(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_genres(records):\n",
    "    genres = set(records[-1]['Genres'].strip().split(\":\"))\n",
    "#                  .to_string(index = False).split(\":\"))\n",
    "    for i in range(len(records) - 1):\n",
    "        cur_genres = records[i]['Genres'].strip().split(\":\")\n",
    "#         .to_string(index = False).split(\";\")\n",
    "        genres.union(cur_genres)\n",
    "\n",
    "    return \":\".join(list(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_publishing_dates(records):\n",
    "    for record in records:\n",
    "        pub_date = record['Publishing Date'].strip()\n",
    "#         .to_string(index = False)\n",
    "        if pub_date is not None and len(pub_date) > 0:\n",
    "            return pub_date\n",
    "        \n",
    "#     pub_date = records[-1]['Publishing Date'].to_string(index = False)\n",
    "#     if pub_date is None or len(pub_date) == 0:\n",
    "#         pub_date = records[0]['Publishing Date'].to_string(index = False)\n",
    "#     return pub_date  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pages(records):\n",
    "    for record in records:\n",
    "        pages = record['Pages'].strip()\n",
    "#         .to_string(index = False)\n",
    "        if pages is not None and len(pages) > 0:\n",
    "            return pages\n",
    "        \n",
    "#     pages = records[-1]['Pages'].to_string(index = False)\n",
    "#     if pages is None or len(pages) == 0:\n",
    "#         pages = records[0]['Pages'].to_string(index = False)\n",
    "#     return pages     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_publishers(records):\n",
    "    for record in records:\n",
    "        publishers = record['Publisher'].strip()\n",
    "#         .to_string(index = False)\n",
    "        if publishers is not None and len(publishers) > 0:\n",
    "            return publishers\n",
    "        \n",
    "#     publishers = records[-1]['Publisher'].to_string(index = False)\n",
    "#     if publishers is None or len(publishers) == 0:\n",
    "#         publishers = records[0]['Publisher'].to_string(index = False)\n",
    "#     return publishers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_languages(records):\n",
    "    for record in records:\n",
    "        languages = record['Language'].strip()\n",
    "#         .to_string(index = False)\n",
    "        if languages is not None and len(languages) > 0:\n",
    "            return languages\n",
    "\n",
    "#     languages = records[-1]['Language'].to_string(index = False)\n",
    "#     if languages is None or len(languages) == 0:\n",
    "#         languages = records[0]['Language'].to_string(index = False)\n",
    "#     return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tuples(records):\n",
    "    final_title = merge_titles(records)\n",
    "    authors = merge_authors(records)\n",
    "    genres = merge_genres(records)\n",
    "    publishing_date = merge_publishing_dates(records)\n",
    "    pages = merge_pages(records)\n",
    "    publisher = merge_publishers(records)\n",
    "    language = merge_languages(records)\n",
    "    final_record = (final_title, authors, genres, publishing_date, pages, publisher, language)\n",
    "\n",
    "    return final_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_map\n",
    "\n",
    "final_records = list()\n",
    "for l_id, r_ids in match_map.items():\n",
    "    records = list()\n",
    "    matches= B.loc[B['id'].isin(r_ids)]\n",
    "    for index, match in matches.iterrows():\n",
    "        records.append(match)\n",
    "    matches = A.loc[A['id'] == l_id]\n",
    "    for index, match in matches.iterrows():\n",
    "        records.append(match)\n",
    "\n",
    "    record = merge_tuples(records)\n",
    "    final_records.append(record)\n",
    "    \n",
    "final_df = pd.DataFrame(final_records, columns=[\"Title\", \"Authors\", \"Genres\", \"Publishing Date\", \"Pages\", \"Publisher\", \"Language\"])\n",
    "# final_df\n",
    "# merged_data\n",
    "merged_data2 = merged_data.append(final_df, ignore_index = True)\n",
    "merged_data2.to_csv(\"unified_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7098"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_data2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS-838",
   "language": "python",
   "name": "entitymatching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
