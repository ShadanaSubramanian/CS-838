{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "\n",
    "A = em.read_csv_metadata('/Users/daravinds/Documents/Projects/CS-838/Stage3-EntityMatching/CS-838-bookdepository.csv',key='id')\n",
    "B = em.read_csv_metadata('/Users/daravinds/Documents/Projects/CS-838/Stage3-EntityMatching/CS-838-goodreads.csv',key='id')\n",
    "#sample_A, sample_B = em.down_sample(A, B, size=500, y_param=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob = em.OverlapBlocker()\n",
    "status=ob.block_tables(A, B, 'Authors', 'Authors', word_level=False, q_val=3, overlap_size=5, l_output_attrs = ['id', 'Title', 'Authors', 'Genres','Publishing Date', 'Pages','Publisher','Language'], r_output_attrs = ['id', 'Title', 'Authors', 'Genres','Publishing Date', 'Pages','Publisher','Language'])\n",
    "status=ob.block_candset(status, 'Title', 'Title', rem_stop_words=True, word_level=False, q_val=3, overlap_size=6 )\n",
    "len(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.919206</td>\n",
       "      <td>0.904099</td>\n",
       "      <td>0.906615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.982213</td>\n",
       "      <td>0.896455</td>\n",
       "      <td>0.933770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.942997</td>\n",
       "      <td>0.569838</td>\n",
       "      <td>0.695597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.947432</td>\n",
       "      <td>0.866567</td>\n",
       "      <td>0.892675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.933237</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.956224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.919206        0.904099    0.906615\n",
       "1            RF           0.982213        0.896455    0.933770\n",
       "2           SVM           0.942997        0.569838    0.695597\n",
       "3        LinReg           0.947432        0.866567    0.892675\n",
       "4        LogReg           0.933237        0.981818    0.956224"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status.to_csv('after_blocking_tuples.csv')\n",
    "S = em.sample_table(status, 500)\n",
    "S.to_csv('sampled_labelled_tuples.csv')\n",
    "\n",
    "S = em.read_csv_metadata(\"labelled_data.csv\", \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n",
    "\n",
    "IJ = em.split_train_test(S, train_proportion=0.5, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']\n",
    "I\n",
    "\n",
    "I.to_csv('train_set.csv')\n",
    "J.to_csv('test_set.csv')\n",
    "\n",
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "\n",
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)\n",
    "F.feature_name\n",
    "\n",
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after=['match'])\n",
    "\n",
    "# Impute feature vectors with the mean of the column values.\n",
    "H = em.impute_table(H, \n",
    "                exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'],\n",
    "                strategy='mean')\n",
    "\n",
    "# Select the best ML matcher using CV\n",
    "result = em.select_matcher([dt, rf, svm, ln, lg], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'],\n",
    "        k=5,\n",
    "        target_attr='match', metric_to_select_matcher='f1', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab = em.AttrEquivalenceBlocker()\n",
    "# status = ab.block_tuples(sample_A.ix[0], sample_B.ix[0], 'name', 'name')\n",
    "# status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob = em.OverlapBlocker()\n",
    "# status=ob.block_tables(A, B, 'Title', 'Title',word_level=False, q_val=3, overlap_size=6, l_output_attrs=['Title'], r_output_attrs=['Title'])\n",
    "# status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 80.0% (88/110)\n",
      "Recall : 92.63% (88/95)\n",
      "F1 : 85.85%\n",
      "False positives : 22 (out of 110 positive predictions)\n",
      "False negatives : 7 (out of 140 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "dt.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='match', show_progress=False)\n",
    "\n",
    "L = L.fillna(0)\n",
    "em.set_property(L, 'key', '_id')\n",
    "\n",
    "# Predict on L \n",
    "predictions = dt.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False, return_probs=True,\n",
    "                        probs_attr='proba')\n",
    "\n",
    "# # Evaluate the predictions\n",
    "em.set_property(predictions, 'fk_ltable', 'ltable_id')\n",
    "em.set_property(predictions, 'fk_rtable', 'rtable_id')\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 90.2% (92/102)\n",
      "Recall : 96.84% (92/95)\n",
      "F1 : 93.4%\n",
      "False positives : 10 (out of 102 positive predictions)\n",
      "False negatives : 3 (out of 148 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "lg.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='match', show_progress=False)\n",
    "\n",
    "L = L.fillna(0)\n",
    "em.set_property(L, 'key', '_id')\n",
    "\n",
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False, return_probs=True,\n",
    "                        probs_attr='proba')\n",
    "\n",
    "# # Evaluate the predictions\n",
    "em.set_property(predictions, 'fk_ltable', 'ltable_id')\n",
    "em.set_property(predictions, 'fk_rtable', 'rtable_id')\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 91.11% (82/90)\n",
      "Recall : 86.32% (82/95)\n",
      "F1 : 88.65%\n",
      "False positives : 8 (out of 90 positive predictions)\n",
      "False negatives : 13 (out of 160 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "rf.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='match', show_progress=False)\n",
    "\n",
    "L = L.fillna(0)\n",
    "em.set_property(L, 'key', '_id')\n",
    "\n",
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False, return_probs=True,\n",
    "                        probs_attr='proba')\n",
    "\n",
    "# # Evaluate the predictions\n",
    "em.set_property(predictions, 'fk_ltable', 'ltable_id')\n",
    "em.set_property(predictions, 'fk_rtable', 'rtable_id')\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 94.44% (51/54)\n",
      "Recall : 53.68% (51/95)\n",
      "F1 : 68.46%\n",
      "False positives : 3 (out of 54 positive predictions)\n",
      "False negatives : 44 (out of 196 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "svm.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='match', show_progress=False)\n",
    "\n",
    "L = L.fillna(0)\n",
    "em.set_property(L, 'key', '_id')\n",
    "\n",
    "# Predict on L \n",
    "predictions = svm.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# # Evaluate the predictions\n",
    "em.set_property(predictions, 'fk_ltable', 'ltable_id')\n",
    "em.set_property(predictions, 'fk_rtable', 'rtable_id')\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no proba function defined for Linear Regression Matcher in scikit learn. So we return the probs as 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 92.86% (78/84)\n",
      "Recall : 82.11% (78/95)\n",
      "F1 : 87.15%\n",
      "False positives : 6 (out of 84 positive predictions)\n",
      "False negatives : 17 (out of 166 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "ln.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='match', show_progress=False)\n",
    "\n",
    "L = L.fillna(0)\n",
    "em.set_property(L, 'key', '_id')\n",
    "\n",
    "# Predict on L \n",
    "predictions = ln.predict(table=L, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False, return_probs=True,\n",
    "                        probs_attr='proba')\n",
    "\n",
    "# # Evaluate the predictions\n",
    "em.set_property(predictions, 'fk_ltable', 'ltable_id')\n",
    "em.set_property(predictions, 'fk_rtable', 'rtable_id')\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS-838",
   "language": "python",
   "name": "entitymatching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
